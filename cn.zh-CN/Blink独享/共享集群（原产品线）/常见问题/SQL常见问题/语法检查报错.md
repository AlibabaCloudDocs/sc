---
keyword: [同名字段, 指定表名, 中文字符, PERIOD FOR SYSTEM\_TIME, 双流JOIN, column '<colunmName\>' is ambiguous, Failed to encode 'xxxx' in character set 'ISO-8859-1', 'Rds' is not supported as a source table, Query result and target table 'table\_name' field length not match, Interval field value 100 exceeds precision of MINUTE\(2\) field, ODPS \*\*\* Partition null table count ODPS tables row count exceeds maxRowCount limit \{2\}, Rowtime attributes must not be in the input rows of a regular join. As a workaround you can cast the time attributes of input tables to TIMESTAMP before, SQL validation failed: index \(55\) must be less than size \(55\), 'Rds' is not supported as a source table]
---

# 语法检查报错

本文汇总了实时计算语法检查常见报错与解决方案。

SQL编写完成后，请您先进行语法检查。如果出现报错信息，请更改SQL后，再上线运行您的作业。常见的语法检查报错信息如下：

-   [报错：column '<colunmName\>' is ambiguous](#section_omf_kko_f4i)
-   [报错：Failed to encode 'xxxx' in character set 'ISO-8859-1'](#section_krn_mfr_o4j)
-   [报错：'Rds' is not supported as a source table](#section_mio_6dk_zkh)
-   [报错：Query result and target table 'table\_name' field length not match](#section_44y_38a_mso)
-   [报错：Interval field value 100 exceeds precision of MINUTE\(2\) field](#section_aml_f5o_6sj)
-   [报错：ODPS \*\*\* Partition null table count ODPS tables row count exceeds maxRowCount limit \{2\}](#section_lcq_dpu_r0h)
-   [报错：Rowtime attributes must not be in the input rows of a regular join. As a workaround you can cast the time attributes of input tables to TIMESTAMP before.](#section_spd_rv9_njx)
-   [报错：SQL validation failed: index \(55\) must be less than size \(55\)](#section_m7a_fxp_pwv)

## 报错：column '<colunmName\>' is ambiguous

-   报错信息

    `column '<colunmName>' is ambiguous`。

-   问题原因

    关联的两张表存在同名字段，在引用时未在字段前指定表名。

-   解决方案
    -   修改前

        ```
        select 
        column_name
        ……
        join table_A.column_name = table_B.column_name
        ```

    -   修改后

        ```
        select 
        table_A.column_name 
        ……
        join table_A.column_name =table_B.column_name
        ```


## 报错：Failed to encode 'xxxx' in character set 'ISO-8859-1'

-   报错信息

    ```
    [ERROR] org.apache.calcite.runtime.CalciteException: Failed to encode ‘【’ in character set ‘ISO-8859-1’[ERROR] Blink-SQL local debug task encountered errororg.apache.calcite.runtime.CalciteException: Failed to encode ‘【’ in character set ‘ISO-8859-1’
    ```

    ![encode报错 ](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9062749951/p84989.png)

-   报错原因

    Flink SQL中不支持直接使用中文字符，包括中文文字和中文标点符号。

-   解决方案

    在中文字符前面添加 \_UTF16。

    ```
    _UTF16'【'
    _UTF16'您好'
    ```

    **说明：** 常量都需要添加`_UTF16`。


## 报错：'Rds' is not supported as a source table

-   报错信息

    ```
     ERR_ID:
          CON-00012
     CAUSE:
          'Rds' is not supported as a source table.
     ACTION:
          Check the doc for more information           
    ```

    !['Rds' is not supported as a source table.](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9062749951/p85142.png)

-   报错原因
    -   作业中声明了RDS的表，但是没有INSERT该表。
    -   RDS作为维表，但是没有声明维表PERIOD FOR SYSTEM\_TIME。
-   解决方案
    -   INSERT作业中声明的RDS表。
    -   在作业中的维表中写入声明PERIOD FOR SYSTEM\_TIME。

## 报错：Query result and target table 'table\_name' field length not match

-   报错信息

    ![ 'table_name' field length not match](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9062749951/p85439.png)

    **说明：** 报错提示中的table\_name指代具体实例中的表名。

-   报错原因

    写入的字段与结果表中声明字段的数量、类型、顺序不一致。

-   解决方案

    修改语句使写入语句的字段数量、类型、顺序都与结果表保持一致。


## 报错：Interval field value 100 exceeds precision of MINUTE\(2\) field

-   报错信息

    在窗口里的年、月、日、时、分、秒设置超过两位数时，语法检查报错。

    ![Interval field value 100](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9062749951/p85442.png)

-   报错原因

    默认的时间隔精度为两位数。

-   解决方案

    建议您在时间单位中更改精度的位数。

    ![解决方案](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9062749951/p85443.png)

    **说明：** 100是三位数，需要在SECOND后面括号内写为3。


## 报错：ODPS \*\*\* Partition null table count ODPS tables row count exceeds maxRowCount limit \{2\}

-   报错信息

    在MaxCompute（ODPS）作为维表时，语法检查报错。

    ![odps](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9062749951/p85448.png)

-   报错原因

    MaxCompute（ODPS）维表数据记录数超过了maxRowCount默认值`100000`。

-   解决方案

    修改maxRowCount参数值，如下图所示。

    ![maxRowCount](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9062749951/p85449.png)


## 报错：Rowtime attributes must not be in the input rows of a regular join. As a workaround you can cast the time attributes of input tables to TIMESTAMP before.

-   报错信息

    ```
    Caused by: org.apache.flink.table.api.TableException: Rowtime attributes must not be in the input rows of a regular join. As a workaround you can cast the time attributes of input tables to TIMESTAMP before.
        at org.apache.flink.table.plan.rules.physical.stream.StreamExecJoinRule.matches(StreamExecJoinRule.scala:64)
        at org.apache.calcite.plan.volcano.VolcanoRuleCall.matchRecurse(VolcanoRuleCall.java:264)
        at org.apache.calcite.plan.volcano.VolcanoRuleCall.match(VolcanoRuleCall.java:248)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.fireRules(VolcanoPlanner.java:1356)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.registerImpl(VolcanoPlanner.java:1629)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.register(VolcanoPlanner.java:861)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.ensureRegistered(VolcanoPlanner.java:881)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.ensureRegistered(VolcanoPlanner.java:100)
        at org.apache.calcite.rel.AbstractRelNode.onRegister(AbstractRelNode.java:334)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.registerImpl(VolcanoPlanner.java:1491)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.register(VolcanoPlanner.java:861)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.ensureRegistered(VolcanoPlanner.java:881)
        at org.apache.calcite.plan.volcano.VolcanoPlanner.changeTraits(VolcanoPlanner.java:546)
        at org.apache.calcite.tools.Programs$RuleSetProgram.run(Programs.java:336)
        at org.apache.flink.table.plan.optimize.FlinkVolcanoProgram.optimize(FlinkVolcanoProgram.scala:56)
        ... 16 more]]     
    ```

-   报错原因

    双流JOIN的ON条件中包含时间属性字段。

-   解决方案
    -   删除双流JOIN中包含时间属性字段的ON条件。
    -   通过CASET或TO\_TIMESTAMP函数处理时间属性字段，然后再进行JOIN。

## 报错：SQL validation failed: index \(55\) must be less than size \(55\)

-   报错信息

    在使用MaxCompute（ODPS）结果表的动态分区功能时，语法检查报错。

    ```
    code:[30017], brief info:[get app plan failed], context info:[detail:
    >>>>>
    org.apache.flink.table.api.ValidationException: 
    ************
    ERR_ID:
         SQL-00120001
    CAUSE:
         SQL validation failed:
         index (55) must be less than size (55)
    ACTION:
         Please see descriptions above. If it doesn't help, please contact customer support for this.
    DETAIL:
    
    ************
    <<<<<]       
    ```

-   报错原因

    MaxCompute（ODPS）结果表DDL语句中没有声明分区列。

-   解决方案

    在DDL语句中声明MaxCompute（ODPS）的分区列。例如示例中的\`partition\` = 'ds=2018\*\*\*\*'。

    ```
    create table odps_output(
        id INT,
        user_name VARCHAR,
        content VARCHAR
    ) with (
        type = 'odps',
        endPoint = 'http://service.cn.maxcompute.aliyun-inc.com/api',
        project = 'projectName',
        tableName = 'tableName',
        accessId = 'yourAccessKeyId',
        accessKey = 'yourAccessKeySecret',
        `partition` = 'ds=2018****'
    );       
    ```

    MaxCompute（ODPS）结果表DDL语句详情，请参见[创建MaxCompute（ODPS）结果表](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL参考/DDL语句/创建数据结果表/数据结果表概述.md)。


