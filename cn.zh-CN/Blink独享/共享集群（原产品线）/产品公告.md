---
keyword: 产品公告
---

# 产品公告

本文为您介绍实时计算Flink版产品公告内容，包括版本更新、功能更新、产品活动等。

## 2021年4月28日-独享模式暂停新购

实时计算Flink版独享模式已于2021年4月28日暂停新购，目前仅支持原有项目的扩缩容和续费操作。如果您有新购需求，推荐使用实时计算[Flink全托管](/cn.zh-CN/Flink全托管/产品概览/概述.md)。如果您有其他问题，请[提交工单](https://selfservice.console.aliyun.com/ticket/createIndex?accounttraceid=f7b76db740fa486baa4b63bd5848fbc1idrb)。

## RocketMQ接入点变更导致实时计算作业适配升级公告

-   升级公告

    因消息队列RocketMQ接入点地域化变更（详情请参见[关于TCP内网接入点设置的公告]()），如果您已使用了Blink 3.7.10以下版本的RocketMQ Connector，则您需要将您的实时计算作业升级至Blink 3.7.10及以上版本，并将作业中EndPoint参数取值更改为新的RocketMQ接入点，EndPoint参数详情请参见：

    -   Blink RocketMQ源表文档：[创建消息队列MQ源表](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL参考/DDL语句/创建数据源表/创建消息队列MQ源表.md)。
    -   Blink RocketMQ结果表文档：[创建消息队列MQ结果表](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL参考/DDL语句/创建数据结果表/创建消息队列MQ结果表.md)。
-   注意事项
    -   旧的RocketMQ接入点在2011年11月后完全不可用，且使用旧的RocketMQ接入点的作业可能存在稳定性风险，因此请您尽快安排作业升级，务必在2021年11月之前完成升级工作。
    -   RocketMQ产品承诺：2021年11月前不会下线旧的RocketMQ接入点，但旧的RocketMQ接入点无法保证作业稳定性。
    -   本次升级会导致作业的State无法兼容，请结合业务情况合理安排升级时间，尽量减少对业务的影响。
    -   2021年11月1日以后，实时计算Flink版产品侧不再对使用了旧的RocketMQ接入点的作业进行维护和支持。

## 2020年8月10日21:00-2020年8月11日02:00-升级公告

2020年8月10日21:00-2020年8月11日02:00，对杭州独享模式管控平台进行升级，升级期间现有运行作业不受影响，但集群创建和扩缩容功能不可用，请知悉。

## 2020年4月28日21:00-2020年4月29日02:00-升级公告

2020年4月28日21:00-2020年4月29日02:00，对上海独享模式管控平台进行升级，升级期间现有运行作业不受影响，但集群扩缩容功能不可用，请知悉。

## 2020年4月20日-2020年4月22日-升级公告

2020年4月20日-2020年4月22日，对上海和深圳共享集群的存储服务进行版本升级，旨在为您提供更加稳定的实时计算Flink版服务。正常情况下，此次升级不会对用户的业务造成影响；特殊情况下，Blink3.2和Blink3.3版本的作业会Failover一次后恢复正常。

## 2019年12月24日-共享模式正式下线

实时计算Flink版共享模式已于2019年12月24日正式下线，将不再支持共享模式新项目的购买，仅支持原有项目的扩缩容和续费操作。如果您有新购需求，推荐使用实时计算Flink版独享模式或Flink半托管模式。

## 2019年8月27日-新增资源配置页签

**开发**页面右侧，新增**资源配置**页签。原控制台**基本属性**页签下的资源配置跳转链接已下线。

## 2019年8月21日-华东2（上海）共享集群扩容通知

2019年8月23日，华东2（上海）共享集群将新增`11.53.0.0/16,11.50.0.0/16`网段。如果您使用的上下游存储涉及到例如RDS、HBase等需要添加白名单的组件，请提前将`11.53.0.0/16,11.50.0.0/16`网段添加至现有的白名单中，防止发生连接异常。

## 2019年5月30日-实时计算Flink版3.0.0以上版本新功能

-   运行信息

    新增Vertex相关信息查询功能，详情请参见[运行信息](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL开发指南/作业运维/运行信息.md)。

-   数据曲线

    新增AutoScaling相关曲线，详情请参见[数据曲线](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL开发指南/作业运维/数据曲线.md)。

-   Timeline

    新增Timeline功能，详情请参见[Timeline](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL开发指南/作业运维/Timeline.md)。

-   属性参数

    新增AutoScale迭代的历史详情查询功能，详情请参见[属性参数](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL开发指南/作业运维/属性参数.md)。


## 2019年5月29日-北京、上海地区实时计算Flink版共享模式停止售卖

自2019年5月29日起，停止售卖北京和上海地区共享模式的实时计算Flink版。

## 2019年3月14日-共享模式默认版本升级为2.2.7

自2019年3月14日起，实时计算Flink版共享模式默认版本升级为[2.2.7](#section_zy1_xlf_4gb)，此次升级仅影响新增作业，不影响原有运行作业。

## 2019年1月24日-Blink-2.2.7版本发布

`Blink-2.2.7`是`Blink-2.x`系列中最新稳定版本，在Blink-1.x版本（最新稳定版本为`Blink-1.6.4`）进行了全面的升级，采用了自主研发的新一代存储Niagara作为Statebackend的底层存储，优化了SQL的性能，增加了一系列新功能：

-   主要特性
    -   SQL
        -   新增Window Emit机制，可以控制Window结果的输出策略，例如：1小时窗口，每1分钟输出一次。
        -   双流Join支持miniBatch，针对不同场景优化了Retraction处理和State存储结构，提高了性能。
        -   AGG支持Filter语法，可以只聚合满足条件的行。
        -   对Local-global AGG进行优化。
        -   重构了SQL的Optimize阶段，解决了SQL编译时间过长的问题。
        -   SortedMapView中KEY支持多种数据类型：BOOLEAN、BYTE、SHORT、INT、LONG、FLOAT、DOUBLE、BIGDECIMAL、BIGINT、BYTE\[\]和STRING。
        -   优化了MIN、MAX、FIRST和LAST函数存在Retraction场景的性能。
        -   新增多种标量函数，例如时区相关的解析TO\_TIMESTAMP\_TZ、格式化DATE\_FORMAT\_TZ和转换函数CONVERT\_TZ。
        -   对SQL和Connector模块的错误信息进行了归类，并对每种类型设计了相应的ERROR\_CODE。
    -   Connector
        -   支持用户自定义的TableFactory注册源表和结果表的Connector。
        -   支持用户通过UDTF方式直接解析数据源类型。
        -   支持读取和写入Kafka。
        -   支持写入到ElasticSearch。
    -   Runtime
        -   通过Blink Session机制，统一了用户提交Job、获取执行结果等行为。
        -   开放了调度插件机制，允许计算模型根据需求自定义调度逻辑。
        -   在有限流的情况下，通过避免不必要的全图重启，提高了JobManager和Task FailOver的处理效率。
    -   StateBackend
        -   使用NiagaraStateBackend替换RocksDBStateBackend，具备更好的读写性能。
        -   `(Experimental) NiagaraStateBackend`支持计算存储分离，支持Failover过程中State秒级恢复。
-   与`Blink1.6.4`不兼容的语法

    |功能项|影响|解决办法|
    |---|--|----|
    |TableFunction接口修改|所有使用自定义TableFunction的用户。|更新代码，实现新的getResultType接口。|
    |ScalarFunction接口修改|所有使用自定义ScalarFunction的用户。|实现新的getResultType接口。|
    |AggregateFunction接口修改|所有使用自定义AggregateFunction的用户。|实现新的getAccumulatorType和getResultType接口。例如，accumulator类型为`Row(STRING, LONG)`，Agg result的类型为STRING，则需要实现如下代码。     ```
public DataType getAccumulatorType\(\) { return
              DataTypes.createRowType\(DataTypes.String, DataTypes.LONG\); } public DataType
              getResultType\(\) { return DataTypes.String; }
    ``` |
    |MapView构造函数修改|MapView构造函数形参类型由之前的TypeInformation变更为DataType。所以在自定义UDAF中声明了MapView的Job都会受影响。|更新代码，按DataType去构造MapView。例如`MapView map = new MapView<>(Types.STRING, Types.INT);`需要更新为`MapView map = new MapView<>(DataTypes.STRING, DataTypes.INT);`。|
    |当参数是LONG或INT时，除法和AVG返回类型改为DOUBLE|以前的除法和AVG函数返回的是入参的字段类型，现在是DOUBLE，会导致类型不匹配的错误。例如：除法和AVG的结果直接写入结果表，可能会报结果表与Query字段类型不匹配的错误。|在除法和AVG的结果上强制加上CAST 。|
    |在比较BigDecimal 和Decimal数据类型的数据时，会考虑精度|用到Decimal的Job，可能会报BigDecimal类型不匹配的错误。|用到Decimal类型的Job，全局替换成带精度的声明方式，`Decimal(38, 18)`。|
    |NULL与字符串的比较语义|`1.x`版本NULL与字符串比较返回True，在`2.x`版本后遵循了SQL语法语义改为返回False。|所有NULL与字符串比较的地方，例如：`WHERE SPLIT_INDEX(shop_list, ':', 1) <> shop_id`，如果`SPLIT_INDEX(shop_list, ':', 1)`返回了NULL，在`1.x`版本上WHERE条件会返回True，在`2.x`上会返回False，将数据过滤。|

-   如何升级到`Blink-2.x`

    使用`Blink-1.x`版本的Job升级到`Blink-2.x`，需要进行数据回溯升级，数据回溯是指用户根据业务需要，在启动Job时，指定启动位点，具体操作如下：

    1.  停止待升级Job（清除State）。
    2.  开发界面单击右下角的**Flink版本**下拉箭头，修改Job的Blink版本为`Blink-2.2.7`，上线Job。
    3.  启动修改后的Job并指定启动位点。

        如果步骤3执行不成功，需要人工介入查明原因后，进行如下操作：

        -   快速修复SQL，重复步骤1、2、3。
        -   如果无法修复SQL，回退到原有Blink版本。
        -   如果无法生成Json Plan，可以尝试设置如下参数：
            -   `blink.job.option.jmMemMB=4096`
            -   `blink.job.submit.timeoutInSeconds=600`
    `Blink-2.0.1`的UDX第三方插件安装包详情，请参见[概述](/cn.zh-CN/Blink独享/共享集群（原产品线）/Flink SQL参考/自定义函数（UDX）/概述.md)。类似如下的异常，是因为UDX包的版本太低或者包冲突导致的。

    ```
    code:[30016], brief info:[get app plan failed], context info:[detail:[java.lang.NoClassDefFoundError: org/apache/flink/table/functions/aggfunctions/DoubleSumWithRetractAggFunction
    at java.lang.ClassLoader.defineClass1(Native Method)
    at java.lang.ClassLoader.defineClass(ClassLoader.java:788)
    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
    ```


