---
keyword: [提交, 作业提交, DataStream, Table API]
---

# 作业提交

本文为您介绍如何提交Flink全托管DataStream API和Table API作业至集群运行。

## 上传JAR包

DataStream API和Table API作业运行前，需要您按照以下步骤将JAR包上传到Flink全托管开发控制台。

1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

3.  在左侧导航栏，单击**资源上传**。

4.  单击**上传资源**，选择您要上传的JAR包。


## 创建作业

1.  登录Flink全托管开发控制台，新建作业。

    1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

    2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

    3.  在左侧导航栏，单击**作业开发**。

    4.  单击**新建**。

    5.  在**新建文件**对话框，填写作业配置信息。

        文件类型请选择为JAR。

        |作业参数|说明|
        |----|--|
        |**文件名称**|作业的名称。 **说明：** 作业名称在当前项目中必须保持唯一。 |
        |**作业类型**|支持以下类型：        -   SQL
        -   JAR
        -   PYTHON |
        |**部署目标**|选择作业需要部署的集群，支持**Per-Job集群**（默认）和**Session集群**两种模式。|

    6.  单击**确认**。

2.  在作业开发页面，填写基本配置信息。

    您可以直接填写以下配置信息，也可以单击**YAML**直接修改配置信息。配置参数解释如下表所示。

    |参数|说明|
    |--|--|
    |部署目标|您可以修改创建作业时已选择的部署目标。|
    |JAR URI|请选择一个文件或者手动上传新文件，您可以拖拽文件到此区域或者单击右侧![上传](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/2491735161/p247547.png)图标选择文件上传。|
    |Entrypoint Class|程序的入口类。**说明：** 如果您的JAR包未指定主类，请在此处输入您的**Entrypoint Class**类的标准路径。 |
    |Entrypoint main args|您可以在此处传入参数，在主方法里面去调用该参数。|
    |附加依赖文件|如果您需要添加更多依赖文件，请选择或者输入任意合法的文件地址。**说明：** |
    |并行度|作业并发数。|

3.  在作业开发页面右侧，单击**高级配置**，根据业务需要填写配置信息。

    参数解释如下表所示。

    |类别|配置项|说明|
    |--|---|--|
    |**常规配置**|Flink版本|支持Flink 1.10、Flink 1.11和Flink 1.12版本。|
    |Flink镜像标签|选择Flink镜像标签。|
    |**行为配置**|恢复策略|当作业状态变为运行时，State的恢复策略。取值如下：    -   Latest Savepoint：将从最新Savepoint文件恢复。
    -   Latest State：将从最新的Savepoint或Checkpoint中恢复。
    -   None：不带State恢复作业，即作业恢复后没有State了，需要重新开始计算了。
**说明：** **升级策略**和**恢复策略**需要配合使用。如果**升级策略**选择**Stateful**，**恢复策略**选择**None**，则完成Savepoint后，作业会从作业的起始时间重新启动，而不是从Savepoint恢复。 |
    |创建实例的最大重试次数|创建实例失败后的重试次数。|
    |Stop with Drain|如果开启Stop With Drain功能，当作业被手动停止或者保留State升级作业时，窗口中已有数据结果会输出，即使没有满足关窗条件。|
    |**Flink配置**|Checkpoint间隔|定时执行Checkpoint的时间间隔。如果不填写，将会关闭 Checkpoint。|
    |两次Checkpoint之间的最短时间间隔|两次Checkpoint之间的最短时间间隔，如果Checkpoint最大并行度是1，则该配置确保两个Checkpoint之间有一个最短时间间隔。|
    |Checkpoint Retention策略|当作业无法再重启或者作业被暂停时，是否需要保留最新完成的Checkpoint。该参数取值如下：    -   Always：作业停止时保留Checkpoint。
    -   Only when FAILED：作业停止后删除Checkpoint。
    -   Never（默认值）：不保留Checkpoint。 |
    |开启Unaligned Checkpoint|开启Unaligned Checkpoint会大大降低反压情况下Checkpoint的总执行时间。但是也会导致增大单次Checkpoint的大小。|
    |Flink重启策略配置|当有Task失败时，如果没有开启Checkpoint，JobManager进程不会重启。如果开启了Checkpoint，则JobManager进程会重启。该参数取值如下：    -   Failure Rate：基于失败率（您填写时间间隔内的最大失败次数）重启。
    -   Fixed Delay：固定间隔重启。
    -   No Restarts（默认值）：不会重启。 |
    |Flink Master 容错配置（高可用性）|该参数取值如下：    -   None（默认值）：表示系统不会保存元数据给JobManager重启恢复时使用。
    -   Kubernetes：表示系统会将元数据保存到Kubernetes 集群中供JobManager重启恢复使用。 |
    |更多Flink配置|在此设置其他Flink配置。例如`taskmanager.numberOfTaskSlots: 1`。|
    |**资源配置**|Task Managers数量|默认与并行度一致。|
    |Job Manager CPUs|默认值为1。|
    |Job Manager Memory|最小值为500 Mi。单位建议使用Gi或Mi，例如，1024 Mi或1.5 Gi。|
    |Task Manager CPUs|默认值为1。|
    |Task Manager Memory|最小值为1 Gi。单位建议使用Gi或Mi，例如，1024 Mi或1.5 Gi。|
    |**日志配置**|Root Log Level|TRACE、DEBUG、INFO、WARN和ERROR。|
    |Log Levels|填写日志名称和日志级别。|
    |Logging Profile|日志模板，可以选择系统模板，也可以选择用户配置。|

4.  您可以在作业开发页面右上角，单击**上线**。


