---
keyword: [配置日志, 配置作业日志]
---

# 配置作业日志

本文为您介绍如何配置作业日志输出到对象存储OSS和日志服务SLS。

在作业正常运行状态下，如果您需要查看当前作业运行日志，您可以单击**Flink UI**进行查看。

如果出现以下情况，则您需要配置作业运行日志到外部存储（OSS或SLS）后，**启动**作业：

-   您需要查看、搜索和分析作业历史运行日志（系统默认保留最近5 MB大小的运行日志）。
-   Flink UI无法打开，需要查看Job Manager日志定位问题。

    **说明：**

    -   如果Task Manger和Job Manager任意一个启动，日志都会写到SLS或OSS。但Task Manger和Job Manager都没有正常启动时，日志不会被写到SLS或OSS。
    -   如果因为Job Manager和Task Manger都没有正常启动，导致您在OSS上没有找到对应的日志文件，请[提交工单](https://selfservice.console.aliyun.com/ticket/createIndex?accounttraceid=f7b76db740fa486baa4b63bd5848fbc1idrb)。

本文从以下场景为您介绍如何配置作业日志：

-   [配置单个作业（新建作业）日志输出到OSS](#section_jqb_mq4_7m7)
-   [配置单个作业（已有作业）日志输出到OSS](#section_n6c_xsy_592)
-   [配置工作空间下所有作业日志输出到OSS](#section_na9_lsd_wqg)
-   [配置单个作业（新建作业）日志输出到SLS](#section_bqc_f3w_d5n)
-   [配置单个作业（已有作业）日志输出到SLS](#section_4q9_16m_s52)
-   [配置工作空间下所有作业日志输出到SLS](#section_dkn_3jb_s94)

## 配置单个作业（新建作业）日志输出到OSS

1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

3.  在左侧导航栏上，单击**创建作业**。

4.  在**基础配置**页面，填写基本配置信息。

5.  单击**显示高级配置**。

6.  在**日志配置**区域，**Logging Profile**选择为**Custom Template**。

7.  将以下文本粘贴到输入框中。

    -   Per-Job模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="20 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="4"/> 
            </Appender>  
            <Appender name="OSS" type="OSS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="baseUri">oss://YOUR-BUCKET-NAME/</Property>
              <Property name="endpoint">https://YOUR-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-OSS-ACCESSKEYID</Property>
              <Property name="accessKeySecret">YOUR-OSS-ACCESSKEYSECRET</Property>
              <Property name="flushIntervalSeconds">10</Property>  
              <Property name="flushIntervalEventCount">100</Property>  
              <Property name="rollingBytes">10485760</Property>  
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="OSS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

    -   Session模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="20 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="4"/> 
            </Appender>  
            <Appender name="OSS" type="OSS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="baseUri">oss://YOUR-BUCKET-NAME/</Property>
              <Property name="endpoint">https://YOUR-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-OSS-ACCESSKEYID</Property>
              <Property name="accessKeySecret">YOUR-OSS-ACCESSKEYSECRET</Property>
              <Property name="flushIntervalSeconds">10</Property>  
              <Property name="flushIntervalEventCount">100</Property>  
              <Property name="rollingBytes">10485760</Property> 
              <Property name="deploymentId">{{ sessionClusterName }}</Property>
              <Property name="jobId">{{ sessionClusterId }}</Property> 
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="OSS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

8.  在自定义模板输入框中，修改以下参数为您OSS Bucket信息。

    |参数|说明|
    |--|--|
    |YOUR-BUCKET-NAME|替换成您OSS Bucket名称。|
    |YOUR-ENDPOINT|替换成您OSS的Endpoint（**ECS的VPC网络访问（内网）** 所在行的**Endpoint（地域节点）**信息）。|
    |YOUR-OSS-ACCESSKEYID|替换成您配置OSS服务账号的**AccessKey ID**。**说明：** 如果您配置与全托管集群同账号下的OSS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的OSS，该参数必填。 |
    |YOUR-OSS-ACCESSKEYSECRET|替换成您配置OSS服务账号的**AccessKey Secret**。**说明：** 如果您配置与全托管集群同账号下的OSS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的OSS，该参数必填。 |
    |sessionClusterName|Session集群的名称。|
    |sessionClusterId|Session集群的ID。|

9.  在页面右下角，单击**创建作业**。

10. 在左侧导航栏上，单击**作业列表**。

11. 单击目标作业名称**操作**列的**启动**。

    您可以在OSS控制台查看作业日志，详情请参见[在OSS上查看作业日志](/cn.zh-CN/Flink全托管/运维管理/查看作业日志.md)。


## 配置单个作业（已有作业）日志输出到OSS

1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

3.  在左侧导航栏上，单击**作业列表**。

4.  单击目标作业名称。

5.  在作业详情页面右上角，单击**编辑**。

6.  单击**显示高级配置**。

7.  在**日志配置**区域，**Logging Profile**选择为**Custom Template**。

8.  将以下文本粘贴到**自定义模板**的输入框中。

    -   Per-Job模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="20 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="4"/> 
            </Appender>  
            <Appender name="OSS" type="OSS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="baseUri">oss://YOUR-BUCKET-NAME/</Property>
              <Property name="endpoint">https://YOUR-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-OSS-ACCESSKEYID</Property>
              <Property name="accessKeySecret">YOUR-OSS-ACCESSKEYSECRET</Property>
              <Property name="flushIntervalSeconds">10</Property>  
              <Property name="flushIntervalEventCount">100</Property>  
              <Property name="rollingBytes">10485760</Property>  
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="OSS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

    -   Session模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="20 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="4"/> 
            </Appender>  
            <Appender name="OSS" type="OSS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="baseUri">oss://YOUR-BUCKET-NAME/</Property>
              <Property name="endpoint">https://YOUR-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-OSS-ACCESSKEYID</Property>
              <Property name="accessKeySecret">YOUR-OSS-ACCESSKEYSECRET</Property>
              <Property name="flushIntervalSeconds">10</Property>  
              <Property name="flushIntervalEventCount">100</Property>  
              <Property name="rollingBytes">10485760</Property> 
              <Property name="deploymentId">{{ sessionClusterName }}</Property>
              <Property name="jobId">{{ sessionClusterId }}</Property> 
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="OSS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

9.  在自定义模板输入框中，修改以下参数为您OSS Bucket信息。

    |参数|说明|
    |--|--|
    |YOUR-BUCKET-NAME|替换成您OSS Bucket名称。|
    |YOUR-ENDPOINT|替换成您OSS的Endpoint（**ECS的VPC网络访问（内网）** 所在行的**Endpoint（地域节点）**信息）。|
    |YOUR-OSS-ACCESSKEYID|替换成您配置OSS服务账号的**AccessKey ID**。**说明：** 如果您配置与全托管集群同账号下的OSS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的OSS，该参数必填。 |
    |YOUR-OSS-ACCESSKEYSECRET|替换成您配置OSS服务账号的**AccessKey Secret**。**说明：** 如果您配置与全托管集群同账号下的OSS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的OSS，该参数必填。 |
    |sessionClusterName|Session集群的名称。|
    |sessionClusterId|Session集群的ID。|

10. 单击**保存**。

11. 在左侧导航栏上，单击**作业列表**。

12. 单击目标作业名称**操作**列的**启动**。

    您可以在OSS控制台查看作业日志，详情请参见[在OSS上查看作业日志](/cn.zh-CN/Flink全托管/运维管理/查看作业日志.md)。


## 配置工作空间下所有作业日志输出到OSS

您可以通过配置**作业模板**的方式，配置工作空间下所有作业日志默认输出到OSS。

1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

3.  在左侧导航栏上，单击**作业模板**。

4.  在**日志配置**区域，**Logging Profile**选择为**Custom Template**。

5.  将以下文本粘贴到**自定义模板**的输入框中。

    -   Per-Job模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="20 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="4"/> 
            </Appender>  
            <Appender name="OSS" type="OSS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="baseUri">oss://YOUR-BUCKET-NAME/</Property>
              <Property name="endpoint">https://YOUR-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-OSS-ACCESSKEYID</Property>
              <Property name="accessKeySecret">YOUR-OSS-ACCESSKEYSECRET</Property>
              <Property name="flushIntervalSeconds">10</Property>  
              <Property name="flushIntervalEventCount">100</Property>  
              <Property name="rollingBytes">10485760</Property>  
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/>
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/> 
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="OSS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

    -   Session模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="20 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="4"/> 
            </Appender>  
            <Appender name="OSS" type="OSS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="baseUri">oss://YOUR-BUCKET-NAME/</Property>
              <Property name="endpoint">https://YOUR-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-OSS-ACCESSKEYID</Property>
              <Property name="accessKeySecret">YOUR-OSS-ACCESSKEYSECRET</Property>
              <Property name="flushIntervalSeconds">10</Property>  
              <Property name="flushIntervalEventCount">100</Property>  
              <Property name="rollingBytes">10485760</Property>  
              <Property name="deploymentId">{{ sessionClusterName }}</Property>
              <Property name="jobId">{{ sessionClusterId }}</Property>
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="OSS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

6.  在自定义模板输入框中，修改以下参数为您OSS Bucket信息。

    |参数|说明|
    |--|--|
    |YOUR-BUCKET-NAME|替换成您OSS Bucket名称。|
    |YOUR-ENDPOINT|替换成您OSS的Endpoint（**ECS的VPC网络访问（内网）** 所在行的**Endpoint（地域节点）**信息）。|
    |YOUR-OSS-ACCESSKEYID|替换成您配置OSS服务账号的**AccessKey ID**。**说明：** 如果您配置与全托管集群同账号下的OSS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的OSS，该参数必填。 |
    |YOUR-OSS-ACCESSKEYSECRET|替换成您配置OSS服务账号的**AccessKey Secret**。**说明：** 如果您配置与全托管集群同账号下的OSS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的OSS，该参数必填。 |
    |sessionClusterName|Session集群的名称。|
    |sessionClusterId|Session集群的ID。|

7.  单击**保存**。

    **说明：** 配置**作业模板**后，后续该工作空间下创建的所有作业的日志都会被存储到OSS。您可以在OSS控制台查看作业日志，详情请参见[在OSS上查看作业日志](/cn.zh-CN/Flink全托管/运维管理/查看作业日志.md)。


## 配置单个作业（新建作业）日志输出到SLS

1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

3.  在左侧导航栏上，单击**创建作业**。

4.  在**基础配置**页面，填写基本配置信息。

5.  单击**显示高级配置**。

6.  **日志模板**选择为**自定义**。

7.  将以下文本粘贴到**自定义模板**的输入框中。

    -   Per-Job模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="5 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="1"/> 
            </Appender>  
            <Appender name="SLS" type="SLS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
        
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="project">YOUR-SLS-PROJECT</Property>  
              <Property name="logStore">YOUR-SLS-LOGSTORE</Property> 
              <Property name="endpoint">YOUR-SLS-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-SLS-ACCESSKEYID</Property> 
              <Property name="accessKeySecret">YOUR-SLS-ACCESSKEYSECRET</Property> 
              <Property name="topic">{{ namespace }}:{{ deploymentId }}:{{ jobId }}</Property> 
              <Property name="flushIntervalSeconds">10</Property>
              <Property name="flushIntervalEventCount">100</Property>
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="SLS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

    -   Session模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="5 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="1"/> 
            </Appender>  
            <Appender name="SLS" type="SLS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
        
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="project">YOUR-SLS-PROJECT</Property>  
              <Property name="logStore">YOUR-SLS-LOGSTORE</Property> 
              <Property name="endpoint">YOUR-SLS-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-SLS-ACCESSKEYID</Property> 
              <Property name="accessKeySecret">YOUR-SLS-ACCESSKEYSECRET</Property> 
              <Property name="topic">{{ namespace }}:{{ deploymentId }}:{{ jobId }}</Property> 
              <Property name="flushIntervalSeconds">10</Property>
              <Property name="flushIntervalEventCount">100</Property>
              <Property name="deploymentId">{{ sessionClusterName }}</Property>
              <Property name="jobId">{{ sessionClusterId }}</Property>
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="SLS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

8.  在**自定义模板**输入框中，修改以下参数。

    |文件夹|说明|
    |---|--|
    |YOUR-SLS-PROJECT|替换成您SLS的Project名称。|
    |YOUR-SLS-LOGSTORE|替换成您SLS的Logstore名称。|
    |YOUR-SLS-ENDPOINT|替换成您SLS所在地域的Endpoint，详情请参见[服务入口](/cn.zh-CN/开发指南/API 参考/服务入口.md)。|
    |YOUR-SLS-ACCESSKEYID|替换成您配置SLS服务账号的**AccessKey ID**。**说明：** 如果您配置与全托管集群同账号下的SLS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的SLS，该参数必填。 |
    |YOUR-SLS-ACCESSKEYSECRET|替换成您配置SLS服务账号的**AccessKey Secret**。**说明：** 如果您配置与全托管集群同账号下的SLS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的SLS，该参数必填。 |
    |sessionClusterName|Session集群的名称。|
    |sessionClusterId|Session集群的ID。|

    **说明：**

    -   请确保您所使用的**AccessKey ID**和**AccessKey Secret**是您开通**Flink全托管**所使用账号下管理的密钥对。
    -   请确保您开通**Flink全托管**服务所使用的账号，有读写该SLS项目的权限。
9.  在页面右下角，单击**创建作业**。

10. 在左侧导航栏上，单击**作业列表**。

11. 单击目标作业名称。

12. 在作业详情页面，单击**启动**。

    您可以在SLS控制台查看作业日志，详情请参见[在SLS上查看作业日志](/cn.zh-CN/Flink全托管/运维管理/查看作业日志.md)。


## 配置单个作业（已有作业）日志输出到SLS

1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

3.  在左侧导航栏上，单击**作业列表**。

4.  单击目标作业名称。

5.  在作业详情页面右上角，单击**编辑**。

6.  单击**显示高级配置**。

7.  **日志模板**选择为**自定义模板**。

8.  将以下文本粘贴到**自定义模板**的输入框中。

    -   Per-Job模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="5 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="1"/> 
            </Appender>  
            <Appender name="SLS" type="SLS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
        
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="project">YOUR-SLS-PROJECT</Property>  
              <Property name="logStore">YOUR-SLS-LOGSTORE</Property> 
              <Property name="endpoint">YOUR-SLS-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-SLS-ACCESSKEYID</Property> 
              <Property name="accessKeySecret">YOUR-SLS-ACCESSKEYSECRET</Property> 
              <Property name="topic">{{ namespace }}:{{ deploymentId }}:{{ jobId }}</Property> 
              <Property name="flushIntervalSeconds">10</Property>
              <Property name="flushIntervalEventCount">100</Property>
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="SLS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

    -   Session模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="5 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="1"/> 
            </Appender>  
            <Appender name="SLS" type="SLS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
        
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="project">YOUR-SLS-PROJECT</Property>  
              <Property name="logStore">YOUR-SLS-LOGSTORE</Property> 
              <Property name="endpoint">YOUR-SLS-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-SLS-ACCESSKEYID</Property> 
              <Property name="accessKeySecret">YOUR-SLS-ACCESSKEYSECRET</Property> 
              <Property name="topic">{{ namespace }}:{{ deploymentId }}:{{ jobId }}</Property> 
              <Property name="flushIntervalSeconds">10</Property>
              <Property name="flushIntervalEventCount">100</Property>
              <Property name="deploymentId">{{ sessionClusterName }}</Property>
              <Property name="jobId">{{ sessionClusterId }}</Property>
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="SLS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

9.  在**自定义模板**输入框中，修改以下参数。

    |文件夹|说明|
    |---|--|
    |YOUR-SLS-PROJECT|替换成您SLS的Project名称。|
    |YOUR-SLS-LOGSTORE|替换成您SLS的Logstore名称。|
    |YOUR-SLS-ENDPOINT|替换成您SLS所在地域的Endpoint，详情请参见[服务入口](/cn.zh-CN/开发指南/API 参考/服务入口.md)。|
    |YOUR-SLS-ACCESSKEYID|替换成您配置SLS服务账号的**AccessKey ID**。**说明：** 如果您配置与全托管集群同账号下的SLS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的SLS，该参数必填。 |
    |YOUR-SLS-ACCESSKEYSECRET|替换成您配置SLS服务账号的**AccessKey Secret**。**说明：** 如果您配置与全托管集群同账号下的SLS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的SLS，该参数必填。 |
    |sessionClusterName|Session集群的名称。|
    |sessionClusterId|Session集群的ID。|

    **说明：**

    -   请确保您所使用的**AccessKey ID**和**AccessKey Secret**是您开通**Flink全托管**所使用账号下管理的密钥对。
    -   请确保您开通**Flink全托管**服务所使用的账号，有读写该SLS项目的权限。
10. 单击**保存**。

11. 在左侧导航栏上，单击**作业列表**。

12. 单击目标作业名称。

13. 在作业详情页面，单击**启动**。

    您可以在SLS控制台查看作业日志，详情请参见[在SLS上查看作业日志](/cn.zh-CN/Flink全托管/运维管理/查看作业日志.md)。


## 配置工作空间下所有作业日志输出到SLS

您可以通过配置**作业模板**的方式，配置工作空间下所有作业日志默认输出到SLS。

1.  登录[实时计算控制台](https://realtime-compute.console.aliyun.com/regions/cn-shanghai)。

2.  在**Flink全托管**页签，单击目标工作空间**操作**列下的**开发控制台**。

3.  在左侧导航栏，单击**系统管理** \> **作业模板**

4.  **日志模板**选择为**自定义模板**。

5.  将以下文本粘贴到**自定义模板**的输入框中。

    -   Per-Job模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="5 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="1"/> 
            </Appender>  
            <Appender name="SLS" type="SLS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
        
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="project">YOUR-SLS-PROJECT</Property>  
              <Property name="logStore">YOUR-SLS-LOGSTORE</Property> 
              <Property name="endpoint">YOUR-SLS-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-SLS-ACCESSKEYID</Property> 
              <Property name="accessKeySecret">YOUR-SLS-ACCESSKEYSECRET</Property> 
              <Property name="topic">{{ namespace }}:{{ deploymentId }}:{{ jobId }}</Property> 
              <Property name="flushIntervalSeconds">10</Property>
              <Property name="flushIntervalEventCount">100</Property>
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="SLS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

    -   Session模式

        ```
        <?xml version="1.0" encoding="UTF-8"?>
        <Configuration xmlns="http://logging.apache.org/log4j/2.0/config" 
        strict="true" packages="com.ververica.platform.logging.appender" status="WARN">  
          <Appenders> 
            <Appender name="StdOut" type="Console"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/> 
            </Appender>  
            <Appender name="RollingFile" type="RollingFile" fileName="${sys:log.file}" filePattern="${sys:log.file}.%i"> 
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
              <Policies> 
                <SizeBasedTriggeringPolicy size="5 MB"/> 
              </Policies>  
              <DefaultRolloverStrategy max="1"/> 
            </Appender>  
            <Appender name="SLS" type="SLS">
              <Layout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS}{GMT+8} %-5p %-60c %x - %m%n" type="PatternLayout"/>  
        
              <!-- The final effective log path is: ${baseUri}/logs/${namespace}/${deploymentId}/{jobId}/ -->
              <Property name="namespace">{{ namespace }}</Property> <!-- Do not modify this line -->
              <Property name="project">YOUR-SLS-PROJECT</Property>  
              <Property name="logStore">YOUR-SLS-LOGSTORE</Property> 
              <Property name="endpoint">YOUR-SLS-ENDPOINT</Property> 
              <Property name="accessKeyId">YOUR-SLS-ACCESSKEYID</Property> 
              <Property name="accessKeySecret">YOUR-SLS-ACCESSKEYSECRET</Property> 
              <Property name="topic">{{ namespace }}:{{ deploymentId }}:{{ jobId }}</Property> 
              <Property name="flushIntervalSeconds">10</Property>
              <Property name="flushIntervalEventCount">100</Property>
              <Property name="deploymentId">{{ sessionClusterName }}</Property>
              <Property name="jobId">{{ sessionClusterId }}</Property>
            </Appender>
          </Appenders>  
          <Loggers> 
            <Logger level="INFO" name="org.apache.hadoop"/>  
            <Logger level="INFO" name="org.apache.kafka"/>  
            <Logger level="INFO" name="org.apache.zookeeper"/>  
            <Logger level="INFO" name="akka"/>  
            <Logger level="ERROR" name="org.jboss.netty.channel.DefaultChannelPipeline"/>  
            <Logger level="OFF" name="org.apache.flink.runtime.rest.handler.job.JobDetailsHandler"/> 
            <Logger level="ERROR" name="org.apache.flink.fs.osshadoop.shaded.com.aliyun.oss"/>
            {%- for name, level in userConfiguredLoggers -%} 
              <Logger level="{{ level }}" name="{{ name }}"/> 
            {%- endfor -%}
            <Root level="{{ rootLoggerLogLevel }}"> 
              <AppenderRef ref="StdOut"/>
              <AppenderRef ref="RollingFile"/>  
              <AppenderRef ref="SLS"/> 
            </Root>
          </Loggers> 
        </Configuration>
        ```

6.  在**自定义模板**输入框中，修改以下参数。

    |文件夹|说明|
    |---|--|
    |YOUR-SLS-PROJECT|替换成您SLS的Project名称。|
    |YOUR-SLS-LOGSTORE|替换成您SLS的Logstore名称。|
    |YOUR-SLS-ENDPOINT|替换成您SLS所在地域的Endpoint，详情请参见[服务入口](/cn.zh-CN/开发指南/API 参考/服务入口.md)。|
    |YOUR-SLS-ACCESSKEYID|替换成您配置SLS服务账号的**AccessKey ID**。**说明：** 如果您配置与全托管集群同账号下的SLS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的SLS，该参数必填。 |
    |YOUR-SLS-ACCESSKEYSECRET|替换成您配置SLS服务账号的**AccessKey Secret**。**说明：** 如果您配置与全托管集群同账号下的SLS，可以不填写该参数，不填写需要删除该参数。如果您配置与全托管集群不同账号下的SLS，该参数必填。 |
    |sessionClusterName|Session集群的名称。|
    |sessionClusterId|Session集群的ID。|

    **说明：**

    -   请确保您所使用的**AccessKey ID**和**AccessKey Secret**是您开通**Flink全托管**所使用账号下管理的密钥对。
    -   请确保您开通**Flink全托管**服务所使用的账号，有读写该SLS项目的权限。
7.  单击**保存更改**。

    **说明：** 配置**作业模板**后，后续该工作空间下创建的所有作业的日志都会被存储到您配置的SLS项目下的Logstore。您可以在SLS控制台查看作业日志，详情请参见[在SLS上查看作业日志](/cn.zh-CN/Flink全托管/运维管理/查看作业日志.md)。


